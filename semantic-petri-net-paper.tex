\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{array}
\usepackage{tabularx}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}

\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}

\usetikzlibrary{shapes,arrows,positioning,automata,petri,fit,calc}

% Code listing settings
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codeblue}{rgb}{0,0,0.8}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codeblue},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

% Define JavaScript language
\lstdefinelanguage{JavaScript}{
  keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break, async, await, const, let, for, of, class, export, import, extends, this, throw, try, finally},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{darkgray}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{purple}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  morestring=[b]',
  morestring=[b]"
}

% TypeScript is similar to JavaScript
\lstdefinelanguage{TypeScript}{
  keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break, async, await, const, let, for, of, class, export, import, extends, this, throw, try, finally, interface, type, implements, namespace, declare, public, private, protected, readonly},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{darkgray}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{purple}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  morestring=[b]',
  morestring=[b]"
}

\title{Beyond Sequential Thinking: How Building an MCP Server Revealed Why AI Agents Fail at Enterprise Workflows}
\author{Aaron Bockelie\\
\textit{Independent Researcher}\\
\texttt{aaronsb@gmail.com}}
\date{July 2025}

\begin{document}

\maketitle

\begin{abstract}
While building a Model Context Protocol (MCP) server for Targetprocess, we discovered architectural patterns that fundamentally challenge how AI agents navigate complex enterprise workflows. Our implementation revealed that successful AI-assisted workflow navigation requires two key patterns: semantic hints that guide next actions, and multi-entry architectures that allow workflows to begin at any logical point. These patterns naturally align with Petri net theory—a mathematical framework for modeling concurrent, distributed systems. This alignment explains why traditional AI agents, built on finite state machine (FSM) assumptions, systematically fail when confronted with the inherently concurrent and multi-path nature of enterprise workflows. This paper documents our journey from building a practical tool to discovering a theoretical framework that reshapes how we think about AI agent architecture.
\end{abstract}

\section{Introduction: The Enterprise Workflow Challenge}

Anyone who has tried to use AI agents for complex enterprise tasks knows the frustration. You ask the agent to ``update the project status,'' and it responds with a rigid sequence: first create a project, then add tasks, then assign team members, and finally—after dozens of unnecessary steps—update the status. But you already have a project. You already have tasks. You just wanted to update the status.

\subsection{The Phone Tree From Hell}

Here's what happened when we first tested our Targetprocess MCP server with a simple request:

\textbf{User}: ``I need to start working on the authentication task''

\textbf{AI Agent (FSM approach - actual transcript)}:

\begin{lstlisting}[language={}]
I'll help you start working on the authentication task. Let me find it for you.

Calling listProjects...
Found 3 projects. Let me check each one.

Calling getProject('CRM-2025')...
This project has 47 tasks. Let me list them.

Calling listTasks('CRM-2025')...
I don't see an authentication task here. Let me check the next project.

Calling getProject('WebApp-Redesign')...
This project has 82 tasks. Searching...

Calling listTasks('WebApp-Redesign')...
I found several auth-related tasks:
- task-1823: "Fix auth timeout"
- task-1901: "Implement OAuth"
- task-2156: "Authentication System"

Which one did you mean? Let me get details on the most likely one.

Calling getTask('task-2156')...
This task is currently assigned to Bob and in Review state. 

Calling getUserInfo('current')...
I see you're Alice. This task is assigned to someone else. Should I reassign it?

Actually, let me first check if you have permissions...
\end{lstlisting}

\textbf{15 tool calls later}: ``I've found the task but there are some complications...''

\hrulefill

\textbf{Same request with Petri net + semantic hints}:

\begin{lstlisting}[language={}]
Calling startWorkingOn('authentication')...

✓ Started working on "Authentication System"
- Task automatically assigned to you
- Status changed to In Progress
- Previous assignee notified

Next steps:
→ The auth library docs are in /docs/auth-guide.md
→ Run 'npm test auth' to verify your changes
→ Use complete_task when ready for review

Suggested commands:
- log_time 2h "Initial implementation"
- link_pull_request 'feat/auth-system'
- add_dependency 'task-2145' (Database schema task)
\end{lstlisting}

\textbf{1 tool call}: Task found, context established, work can begin.

This pattern repeats across enterprise tools: AI agents assume every interaction starts from zero, following predetermined paths that rarely match how real work happens. Teams don't follow linear workflows. A developer might jump directly to logging time on a bug. A project manager might start by reviewing team capacity. A tester might begin by reopening a supposedly fixed issue. Real workflows have multiple entry points, concurrent activities, and context-dependent paths.

We encountered this challenge firsthand while building an MCP server for Targetprocess, an agile project management platform. What started as a straightforward integration project became a journey of discovery that would fundamentally change how we think about AI agents and enterprise workflows.

The problem wasn't just technical—it was conceptual. Traditional AI agents are built on finite state machine (FSM) principles: start here, follow this path, end there. But enterprise workflows don't work that way. They're more like busy intersections where multiple paths converge and diverge, where the right next step depends on who you are, what you're doing, and where you've been.

This paper tells the story of how we discovered a better way. Through iterative development and real-world testing, we identified two architectural patterns that transformed our MCP server from a frustrating maze into an intuitive assistant. More surprisingly, we realized these patterns weren't new—they aligned perfectly with Petri net theory, a mathematical framework developed in the 1960s for modeling concurrent systems.

This discovery explains not just why our solution worked, but why traditional AI agents systematically fail at enterprise workflows. It's not a bug—it's a fundamental mismatch between tool architecture and workflow reality.

\section{Visual Comparison: FSM vs Our Discovery}

\subsection{The Fundamental Mismatch Visualized}

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
% FSM Approach
\node[draw,rectangle,rounded corners] (start) {Start};
\node[draw,rectangle,right=of start] (list) {List Projects};
\node[draw,rectangle,right=of list] (select) {Select Project};
\node[draw,rectangle,right=of select] (tasks) {List Tasks};
\node[draw,rectangle,below=of tasks] (selecttask) {Select Task};
\node[draw,rectangle,left=of selecttask] (check) {Check State};
\node[draw,rectangle,left=of check] (update) {Update State};
\node[draw,rectangle,left=of update] (done) {Done};

\draw[->] (start) -- (list);
\draw[->] (list) -- (select);
\draw[->] (select) -- (tasks);
\draw[->] (tasks) -- (selecttask);
\draw[->] (selecttask) -- (check);
\draw[->] (check) -- (update);
\draw[->] (update) -- (done);

\node[above=2cm of select,font=\bfseries] {FSM Approach};
\end{tikzpicture}

\vspace{1cm}

\begin{tikzpicture}[node distance=2cm]
% Petri Net with Semantic Hints
\node[draw,circle,fill=pink!30] (p1) {Start};
\node[draw,rectangle,fill=blue!20,right=of p1] (t1) {Multi-Entry};
\node[draw,circle,above right=of t1] (p2) {Task Found};
\node[draw,circle,right=of t1] (p3) {Bug Found};
\node[draw,circle,below right=of t1] (p4) {Project Found};
\node[draw,rectangle,fill=blue!20,right=3cm of t1] (t2) {Semantic Op};
\node[draw,circle,right=of t2] (p5) {Context Est.};
\node[draw,circle,fill=green!30,right=of p5] (p6) {Work Begins};

\draw[->] (p1) -- (t1);
\draw[->] (t1) -- (p2);
\draw[->] (t1) -- (p3);
\draw[->] (t1) -- (p4);
\draw[->] (p2) -- (t2);
\draw[->] (p3) -- (t2);
\draw[->] (p4) -- (t2);
\draw[->] (t2) -- (p5);
\draw[->] (p5) -- (p6);

\node[draw,rectangle,dashed,below=of p5] (h1) {Hint: Next Steps};
\node[draw,rectangle,dashed,below=of h1] (h2) {Hint: Suggestions};
\draw[dashed,->] (p5) -- (h1);
\draw[dashed,->] (p5) -- (h2);

\node[above=2cm of t1,font=\bfseries] {Petri Net with Semantic Hints};
\end{tikzpicture}
\caption{Comparison of FSM and Petri Net approaches to workflow navigation}
\end{figure}

\subsection{Why FSMs Fail at Real Workflows: State Explosion}

Consider a simple workflow with just 3 users and 4 task states. An FSM must explicitly model every combination:

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=2cm,auto]
\node[state,initial] (unassigned) {Unassigned};
\node[state,right=of unassigned] (alice) {Assigned to Alice};
\node[state,below=of unassigned] (bob) {Assigned to Bob};
\node[state,below=of alice] (carol) {Assigned to Carol};
\node[state,right=of alice] (aliceprog) {Alice In Progress};
\node[state,right=of bob] (bobprog) {Bob In Progress};
\node[state,right=of carol] (carolprog) {Carol In Progress};

\draw[->] (unassigned) edge node {assign(Alice)} (alice);
\draw[->] (unassigned) edge node {assign(Bob)} (bob);
\draw[->] (unassigned) edge node {assign(Carol)} (carol);
\draw[->] (alice) edge node {start()} (aliceprog);
\draw[->] (bob) edge node {start()} (bobprog);
\draw[->] (carol) edge node {start()} (carolprog);

\node[draw,rectangle,text width=6cm,below=1cm of carolprog] {With just 3 users and 4 states,\\we need 12 combined states!\\Real systems have 100s of users...};
\end{tikzpicture}
\caption{State explosion in FSM-based workflow modeling}
\end{figure}

\subsection{The Petri Net Advantage: Concurrent Tokens}

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=3cm]
% Places
\node[place,label=above:Open Tasks,fill=yellow!30] (p1) {P1};
\node[place,label=above:In Progress,fill=cyan!30,right=of p1] (p2) {P2};
\node[place,label=above:Review,fill=pink!30,right=of p2] (p3) {P3};
\node[place,label=below:Testing,below=of p3] (p4) {P4};
\node[place,label=below:Done,left=of p4] (p5) {P5};

% Transitions
\node[transition,below=1cm of p1] (t1) {start\_work};
\node[transition,below=1cm of p2] (t2) {complete};
\node[transition,right=of p3] (t3) {test};
\node[transition,below=of p5] (t4) {verify};

% Arcs
\draw[->] (p1) -- (t1);
\draw[->] (t1) -- (p2);
\draw[->] (p2) -- (t2);
\draw[->] (t2) -- (p3);
\draw[->] (p3) -- (t3);
\draw[->] (t3) -- (p4);
\draw[->] (p4) -- (t4);
\draw[->] (t4) -- (p5);

% Tokens
\node[token,tokens=1,label=left:{\small Task-Auth}] at (p1) {};
\node[token,tokens=1,label=left:{\small Bug-Login}] at (p2) {};
\node[token,tokens=1,label=right:{\small Task-API}] at (p3) {};

\node[draw,rectangle,text width=6cm,below=2cm of t4] {Multiple tokens can exist\\in different places\\simultaneously!};
\end{tikzpicture}
\caption{Petri net representation with concurrent tokens}
\end{figure}

\textbf{Key Insight}: In FSMs, the entire system has one state. In Petri nets, each work item (token) has its own state, enabling natural concurrency.

\section{A Petri Net Primer}

\subsection{What Are Petri Nets?}

Imagine a busy restaurant kitchen. Orders (tokens) move through different stations (places) - prep, cooking, plating, serving. Multiple orders are at different stages simultaneously. Chefs (transitions) move orders between stations when conditions are right. This is a Petri net.

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=3cm]
\node[place,label=above:Order Queue,fill=red!20] (o1) {};
\node[transition,right=of o1] (t1) {Chef Preps};
\node[place,label=above:Prep Station,fill=green!20,right=of t1] (o2) {};
\node[transition,right=of o2] (t2) {Cook};
\node[place,label=above:Cooking,fill=blue!20,right=of t2] (o3) {};
\node[transition,below=of o3] (t3) {Plate};
\node[place,label=below:Ready to Serve,fill=yellow!20,left=of t3] (o4) {};

\draw[->] (o1) -- (t1);
\draw[->] (t1) -- (o2);
\draw[->] (o2) -- (t2);
\draw[->] (t2) -- (o3);
\draw[->] (o3) -- (t3);
\draw[->] (t3) -- (o4);

% Tokens
\node[token,tokens=1,label=left:{\small 🍕 Pizza}] at (o1) {};
\node[token,tokens=1,label=above:{\small 🍝 Pasta}] at (o2) {};
\node[token,tokens=1,label=right:{\small 🥗 Salad}] at (o3) {};
\end{tikzpicture}
\caption{Restaurant kitchen modeled as a Petri net}
\end{figure}

\textbf{Core Concepts}:
\begin{itemize}
\item \textbf{Places} (circles): Possible states or locations - ``Order Queue'', ``Cooking'', ``Ready''
\item \textbf{Transitions} (rectangles): Actions that move items - ``Chef Preps'', ``Cook'', ``Plate''
\item \textbf{Tokens} (items): The actual things moving through - individual orders
\item \textbf{Arcs} (arrows): Valid paths between places and transitions
\end{itemize}

\subsection{FSM vs Petri Net: The Critical Difference}

In an FSM, the system has one global state:
\begin{itemize}
\item Current State: ``Cooking Pasta''
\item ❌ Can't track pizza in prep
\item ❌ Can't track salad being plated
\item ❌ Must finish pasta first
\end{itemize}

In a Petri net, multiple concurrent states exist:
\begin{itemize}
\item Pizza: In Prep
\item Pasta: Cooking
\item Salad: Being Plated
\item ✅ All tracked simultaneously
\item ✅ Natural representation
\item ✅ Matches reality
\end{itemize}

\subsection{Why This Matters for AI Agents}

In enterprise workflows, you're not tracking one thing - you're juggling many:

\textbf{Developer Reality}:
\begin{itemize}
\item Task A: In code review
\item Task B: Writing tests
\item Bug C: Investigating
\item Meeting D: Scheduled
\item PR E: Waiting for CI
\end{itemize}

An FSM-based agent would need states like ``InReviewWhileTestingWhileInvestigatingWhileWaitingForCI'' - impossible! A Petri net simply has tokens in different places.

\subsection{The Semantic Hints Connection}

Our semantic hints are actually Petri net \textbf{firing rules} - they tell you which transitions are enabled:

\begin{lstlisting}[language=JavaScript]
// This is a Petri net transition with firing rules!
if (task.state === "In Progress" && task.testsPass) {
  return {
    nextSteps: [
      "Ready for code review",        // Transition enabled
      "All tests passing",             // Precondition met
      "Documentation updated"          // Another precondition
    ],
    suggestions: [
      "moveToReview()",               // Fire this transition
      "requestReviewer('senior-dev')", // Related transition
      "updatePR()"                    // Parallel transition
    ]
  };
}
\end{lstlisting}

The hints aren't just helpful messages - they're encoding the Petri net structure!

\section{The Evolution: From API Wrapper to Petri Net Executor}

\subsection{The Naive Beginning}

We started with conventional patterns, creating tools that mirrored API endpoints:

\begin{lstlisting}[language=JavaScript]
// Simple API wrapper approach
async function updateTaskState(taskId, state) {
  return await api.update(`/tasks/${taskId}`, { state });
}
\end{lstlisting}

It worked—technically. But using it felt like navigating a phone tree from hell. Every simple request triggered a cascade of tool calls as the AI agent tried to establish context.

\subsection{The Semantic Hints Emergence}

Watching the AI struggle, we realized the core issue: tools returned data but no guidance. The agent knew what happened but not what should happen next.

\begin{lstlisting}[language=JavaScript]
// Semantic hints emerge
async function updateTaskState(taskId, state) {
  const result = await api.update(`/tasks/${taskId}`, { state });
  return {
    ...result,
    message: `Task updated to ${state}`,
    nextSteps: [
      'Task state changed successfully',
      'You can now log time if working on it',
      'Consider updating related tasks'
    ],
    suggestions: [
      `log_time ${taskId} "2h" "Working on implementation"`,
      `add_comment ${taskId} "Started work"`,
      `complete_task ${taskId}`
    ]
  };
}
\end{lstlisting}

\subsection{Full Multi-Entry Pattern}

The final evolution: tools that work from any starting point:

\begin{lstlisting}[language=JavaScript]
// Full Petri net pattern implementation
async function startWorkingOn(identifier, context) {
  // Find the task flexibly (ID, name, or partial match)
  const task = await findTask(identifier);
  
  // Establish necessary context (check preconditions)
  if (!isAssigned(task, context.user)) {
    await assignTask(task, context.user);
  }
  
  // Transition to appropriate state (fire transition)
  const targetState = await discoverState("In Progress");
  if (task.state !== targetState) {
    await transitionTask(task, targetState);
  }
  
  // Return semantic guidance (output arcs!)
  return {
    success: true,
    entity: task,
    message: `Started working on ${task.name}`,
    nextSteps: generateWorkflowSteps(task, context),
    suggestions: generateContextualSuggestions(task, context)
  };
}
\end{lstlisting}

\section{The ``Aha'' Moment: Recognizing Petri Nets}

\subsection{The Semantic Hints ARE Petri Net Arcs}

As we documented these patterns, it clicked: we had accidentally implemented a Petri net executor:

\begin{lstlisting}[language=JavaScript]
// This looks like a simple return structure...
return {
  success: true,
  entity: task,
  nextSteps: [        // But these ARE the output arcs!
    'Task marked as complete',
    'You can now create a pull request',
    'Consider updating test documentation'
  ],
  suggestions: [      // And these ARE the enabled transitions!
    'create_pr "Implements ' + task.name + '"',
    'find_related_tests',
    'start_next_task'
  ]
};
\end{lstlisting}

\subsection{Mapping to Petri Net Theory}

Our architecture mapped perfectly to Petri net concepts:

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Our Implementation} & \textbf{Petri Net Concept} & \textbf{Why It Works} \\
\hline
Task states & Places & Multiple states can be active \\
Semantic operations & Transitions & Context-aware firing rules \\
Work items & Tokens & Flow through the network \\
nextSteps/suggestions & Arcs & Guide token movement \\
\hline
\end{tabular}
\caption{Mapping between implementation and Petri net concepts}
\end{table}

This realization came only after months of development. Let's go back to the beginning and trace how we got here.

\section{Building the Solution: The Full Journey}

\subsection{The Initial Challenge}

Our goal seemed straightforward: build an MCP server that would help AI agents interact with Targetprocess. The Model Context Protocol provides a standardized way for AI assistants to access external tools and data sources. In theory, we just needed to wrap Targetprocess's API in MCP-compatible tools.

The first implementation followed conventional patterns. We created tools that mirrored API endpoints:
\begin{itemize}
\item \texttt{get\_projects()} - List all projects
\item \texttt{create\_task(project\_id, name, description)} - Create a new task
\item \texttt{update\_task\_state(task\_id, state)} - Change task state
\item \texttt{assign\_user(task\_id, user\_id)} - Assign task to user
\end{itemize}

\subsection{The First Breakthrough: Semantic Hints}

Watching the AI struggle with endless tool calls, we realized the core issue: tools returned data but no guidance. The agent knew what happened but not what should happen next. It was like giving someone a map with no indication of where they were or where they should go.

We started experimenting with richer return values. Instead of just confirming an action succeeded, tools began providing hints about logical next steps:

\begin{lstlisting}[language=JavaScript]
// Before: Just data
return {
  success: true,
  task: { id: 123, state: "In Progress" }
};

// After: Data plus guidance
return {
  success: true,
  entity: task,
  message: `Started working on ${task.Name}`,
  nextSteps: [
    'Task state updated to In Progress',
    'You can now log time using log_time operation',
    'Complete the task when done using complete_task'
  ],
  suggestions: [
    `log_time 2h "Initial investigation"`,
    `add_comment "Started working on this"`,
    `complete_task`
  ]
};
\end{lstlisting}

The transformation was immediate. The AI agent stopped wandering through endless tool calls and started following contextual workflows. But this created a new problem: the hints assumed linear progression. What if someone wanted to log time on a task that wasn't ``In Progress''? What if they needed to reopen a completed task?

\subsection{The Second Breakthrough: Multi-Entry Workflows}

Traditional workflow systems enforce entry points. You must create a project before adding tasks. You must assign a task before logging time. These constraints make sense for data integrity but create terrible user experiences.

We redesigned our tools to work from any starting point. Each tool became intelligent enough to handle missing context:

\begin{itemize}
\item \texttt{start\_task(identifier)} - Accepts task ID, task name, or even partial matches
\item \texttt{log\_time(identifier, duration, description)} - Works whether the task is assigned or not
\item \texttt{find\_my\_work()} - Starts from the user's perspective, not the system's hierarchy
\end{itemize}

The implementation required each tool to be more sophisticated:

\begin{lstlisting}[language=JavaScript]
async function startTask(identifier) {
  // Find the task by ID, name, or partial match
  let task = await findTask(identifier);
  
  // Check if user is assigned
  if (!task.Assignments.includes(currentUser)) {
    // Automatically assign if not already
    await assignTask(task.id, currentUser.id);
  }
  
  // Transition to In Progress if needed
  if (task.State !== "In Progress") {
    await transitionTask(task.id, "In Progress");
  }
  
  // Return rich context
  return {
    success: true,
    entity: task,
    message: `Started working on ${task.Name}`,
    nextSteps: generateNextSteps(task, currentUser),
    suggestions: generateSuggestions(task, currentUser)
  };
}
\end{lstlisting}

This pattern—tools that adapt to context rather than enforcing preconditions—transformed the user experience. The AI agent could now handle requests the way humans actually work.

\subsection{Role-Based Adaptation}

Different users interact with Targetprocess differently. We implemented persona-based tool selection and hint generation:

\begin{itemize}
\item \textbf{Developers} see code-related tools and technical suggestions
\item \textbf{Project Managers} get planning tools and team overview hints  
\item \textbf{Testers} receive testing workflows and bug tracking guidance
\end{itemize}

This wasn't just about filtering tools—the semantic hints themselves adapted to role context.

\subsection{The Architecture That Emerged}

By the end of development, our MCP server had evolved far from a simple API wrapper. Key architectural patterns included:

\begin{enumerate}
\item \textbf{Semantic Response Objects}: Every tool returned structured guidance
\item \textbf{Context-Aware Entry Points}: Tools worked from any starting state
\item \textbf{Dynamic Workflow Discovery}: Next steps generated based on current state
\item \textbf{Role-Based Adaptation}: Different paths for different users
\item \textbf{Stateless Intelligence}: Each tool call contained full context
\end{enumerate}

\section{The Theory-Practice Bridge: Why This Matters}

\subsection{Current State of AI Agents}

Look at any AI agent trying to navigate Jira, Azure DevOps, or similar tools. The pattern is consistent:

\begin{lstlisting}[language=JavaScript]
// What AI agents do today (FSM thinking)
async function updateTaskStatus(taskId, newStatus) {
  const projects = await api.listProjects();
  for (const project of projects) {
    const tasks = await api.listTasks(project.id);
    const task = tasks.find(t => t.id === taskId);
    if (task) {
      if (task.status === 'Open' && newStatus === 'In Progress') {
        if (!task.assignee) {
          throw new Error('Must assign task first');
        }
        return await api.updateStatus(taskId, newStatus);
      }
      // ... endless state checks ...
    }
  }
}
\end{lstlisting}

This fails because it assumes:
\begin{enumerate}
\item Sequential discovery (must find project first)
\item Single state path (Open → In Progress → Done)
\item Global consistency (everyone follows same flow)
\end{enumerate}

\subsection{Our Discovery}

We discovered real workflows are concurrent graphs, not sequential paths:

\begin{lstlisting}[language=JavaScript]
// What we built (Petri net thinking)
async function startWorkingOn(identifier) {
  // Multiple entry points - token can enter anywhere
  const task = await findTaskByAnyMeans(identifier);
  
  // Check preconditions (input places)
  const preconditions = await checkWhatNeedsFixing(task);
  
  // Fire all necessary transitions in parallel
  await Promise.all([
    preconditions.needsAssignment && assignToMe(task),
    preconditions.wrongState && transitionToWorking(task),
    preconditions.missingContext && establishContext(task)
  ]);
  
  // Return postconditions (output places)
  return {
    success: true,
    currentPlaces: getTokenLocations(task),
    enabledTransitions: getWhatCanHappenNext(task),
    parallelPossibilities: getWhatElseIsHappening()
  };
}
\end{lstlisting}

\subsection{The Bridge: Theory Explains Practice}

The Petri net model explains our success:

\subsubsection{Multiple Tokens = Multiple Work Items}

\textbf{Practice}: Developers work on many things simultaneously

\begin{lstlisting}[language=JavaScript]
// FSM forces serialization
doTask1(); then doTask2(); then doTask3();

// Petri net allows true concurrency
parallel([
  workOn(task1),  // Token 1 in "coding" place
  review(task2),  // Token 2 in "review" place  
  test(task3)     // Token 3 in "testing" place
]);
\end{lstlisting}

\textbf{Theory}: Petri nets model distributed systems where multiple activities happen independently

\subsubsection{Places = States, Transitions = Actions}

\textbf{Practice}: Our semantic hints encode valid transitions

\begin{lstlisting}[language=JavaScript]
return {
  currentPlace: "In Review",
  enabledTransitions: [
    "approve → Testing",
    "reject → In Progress",
    "comment → Still In Review"
  ]
};
\end{lstlisting}

\textbf{Theory}: This is literally a Petri net marking with enabled transitions!

\subsubsection{Firing Rules = Business Logic}

\textbf{Practice}: Complex conditions for state changes

\begin{lstlisting}[language=JavaScript]
// Can only deploy if ALL conditions met
if (allTestsPass && approved && stagingWorks) {
  enableTransition('deploy');
}
\end{lstlisting}

\textbf{Theory}: Petri net transitions fire when all input places have tokens

\subsubsection{Reachability = Workflow Possibilities}

\textbf{Practice}: Multi-entry architecture

\begin{lstlisting}[language=JavaScript]
// Any of these reaches the same goal
startFromScratch() → implement() → test() → done
fixBugInProduction() → test() → done  
resumeAfterVacation() → test() → done
\end{lstlisting}

\textbf{Theory}: Petri net reachability analysis proves multiple paths exist

\subsection{Why This Changes Everything}

The mismatch isn't a minor implementation detail - it's fundamental:

\begin{table}[H]
\centering
\begin{tabularx}{\textwidth}{|l|X|X|X|}
\hline
\textbf{Aspect} & \textbf{FSM Reality} & \textbf{Workflow Reality} & \textbf{Petri Net Solution} \\
\hline
State & One global state & Many concurrent states & Tokens in places \\
\hline
Transitions & Sequential only & Parallel \& conditional & Concurrent firing \\
\hline
Entry & Single start point & Multiple entry points & Tokens anywhere \\
\hline
Context & Global context & Local contexts & Token attributes \\
\hline
Guidance & None & Essential & Enabled transitions \\
\hline
\end{tabularx}
\caption{Comparison of FSM limitations versus Petri net capabilities}
\end{table}

By building with Petri net patterns (even unknowingly), we aligned with how work actually happens instead of how computers traditionally model it.

\section{Petri Nets Hidden in Plain Sight}

Our ``discovery'' of Petri net patterns isn't unique. Major software systems have quietly used these patterns for decades when faced with the same fundamental challenge: managing concurrent, distributed processes.

\subsection{Industrial Automation}
\textbf{SIEMENS SIMATIC} and \textbf{Schneider Electric Unity Pro} use Petri net-based models for industrial control:
\begin{itemize}
\item Sequential Function Charts (SFC) are essentially Petri nets
\item Grafcet (used in Unity Pro) is explicitly a type of Petri net
\item Why? Factory automation involves multiple concurrent processes that FSMs can't model
\end{itemize}

\subsection{Enterprise Software}
\textbf{Microsoft Windows Workflow Foundation} uses state machine concepts derived from Petri nets:
\begin{itemize}
\item Particularly in complex approval workflows
\item Multi-party processes with parallel approvals
\item The same patterns we discovered, formalized years ago
\end{itemize}

\textbf{YAWL (Yet Another Workflow Language)}:
\begin{itemize}
\item Open-source workflow system explicitly based on Petri nets
\item Used by organizations for complex business process automation
\item Directly implements the patterns we ``discovered''
\end{itemize}

\subsection{Software Development Tools}
Even \textbf{Git} internally uses concepts similar to Petri nets:
\begin{itemize}
\item The DAG (Directed Acyclic Graph) structure for commits
\item Merge operations are essentially Petri net transitions
\item Concurrent development branches are tokens in different places
\end{itemize}

\subsection{Business Process Management}
\textbf{ProM Framework} uses Petri nets for process mining:
\begin{itemize}
\item Analyzes actual business processes from event logs
\item Discovers the real workflows (not the documented ones)
\item Companies use it to find how work actually flows—spoiler: it's not linear
\end{itemize}

\subsection{Mission-Critical Systems}
\textbf{NASA} and \textbf{Bell Labs} use Promela/SPIN for protocol verification:
\begin{itemize}
\item Models concurrent systems using Petri net-like concepts
\item Why? Because spacecraft systems and telecom protocols are inherently concurrent
\item FSMs would require modeling every possible state combination—impossible at scale
\end{itemize}

\subsection{The Pattern is Clear}

These systems didn't choose Petri nets for academic reasons. They evolved to use them because:
\begin{enumerate}
\item Real-world processes are concurrent
\item FSMs create state explosion
\item Petri nets naturally model what's actually happening
\end{enumerate}

\subsection{Why Are AI Agents Different?}

The disconnect is striking. While industrial control systems figured this out in the 1980s, AI agents in 2025 still assume sequential processes. Why?

\begin{enumerate}
\item \textbf{Historical Accident}: Early chatbots were simple state machines, and we never questioned the assumption
\item \textbf{Tool Limitations}: Most AI frameworks provide FSM-like primitives (chains, sequences)
\item \textbf{Mental Models}: Developers think in functions calls, not concurrent processes
\item \textbf{Lack of Cross-Domain Learning}: AI researchers rarely study industrial automation
\end{enumerate}

\subsection{The Irony}

We're using AI to control systems that themselves use Petri nets. An AI agent trying to manage a SIEMENS factory automation system is using an FSM to control a Petri net—no wonder it fails!

This isn't about choosing obscure academic theory. It's about aligning with patterns that production systems have validated for decades. Our accidental discovery simply rediscovered what industrial engineers have known all along: \textbf{concurrent processes need concurrent models}.

\section{Implementation Insights: Real Code from the Journey}

With this broader context of Petri nets in production systems, let's examine how these same patterns emerged in our own implementation. The code evolution tells a story of gradually discovering what others had already found through different paths.

\subsection{The Evolution in Code}

Looking at the actual implementation reveals how these patterns emerged:

\subsubsection{Early Days: Simple API Wrappers}

\begin{lstlisting}[language=TypeScript]
// From initial commits - direct API wrapping
export class GetEntityTool extends BaseTool {
  async execute(args: { entity: string, id: number }) {
    const result = await this.api.get(`/${args.entity}/${args.id}`);
    return { entity: result };
  }
}
\end{lstlisting}

\subsubsection{The Semantic Layer Emerges}

\begin{lstlisting}[language=TypeScript]
// From semantic-operation.interface.ts - the pattern crystallizes
export interface OperationResult {
  content: Array<{
    type: 'text' | 'structured-data' | 'error';
    text?: string;
    data?: any;
  }>;
  
  suggestions?: string[];  // These ARE the Petri net output arcs!
  
  affectedEntities?: Array<{
    id: number;
    type: string;
    action: 'created' | 'updated' | 'deleted';
  }>;
}
\end{lstlisting}

\subsubsection{Multi-Entry in Action}

\begin{lstlisting}[language=TypeScript]
// From start-working-on.ts - multiple ways to find work
private async findTask(identifier: string): Promise<any> {
  // Try as ID first
  if (/^\d+$/.test(identifier)) {
    return await this.service.getEntity('Task', parseInt(identifier));
  }
  
  // Try exact name match
  const exactMatch = await this.service.searchEntities(
    'Task',
    `Name eq '${identifier}'`
  );
  if (exactMatch.Items.length === 1) return exactMatch.Items[0];
  
  // Try fuzzy search
  const fuzzyMatch = await this.service.searchEntities(
    'Task', 
    `Name contains '${identifier}'`
  );
  if (fuzzyMatch.Items.length > 0) {
    // Return best match based on context
    return this.selectBestMatch(fuzzyMatch.Items, identifier);
  }
  
  throw new Error(`No task found matching: ${identifier}`);
}
\end{lstlisting}

\subsubsection{Context-Aware Suggestions}

\begin{lstlisting}[language=TypeScript]
// From operation-registry.ts - Petri net firing rules!
private calculateContextRelevance(
  operation: SemanticOperation, 
  context: ExecutionContext
): number {
  let relevance = 0;

  // Previous operation creates enabled transitions
  const lastOp = context.conversation.previousOperations.slice(-1)[0];
  
  if (lastOp === 'show-my-tasks' && operation.id === 'start-working-on') {
    relevance += 5;  // Natural flow: see tasks → start one
  }
  
  if (lastOp === 'start-working-on' && operation.id === 'log-time') {
    relevance += 4;  // Common pattern: start → track time
  }
  
  // Entity context enables operations
  if (context.hasEntity('Task', 'In Progress')) {
    if (operation.id === 'complete-task') relevance += 3;
    if (operation.id === 'pause-work') relevance += 2;
  }
  
  return relevance;
}
\end{lstlisting}

\subsubsection{Dynamic State Discovery}

\begin{lstlisting}[language=TypeScript]
// From complete-task.ts - no hardcoded states!
private async discoverNextState(
  currentState: string,
  task: any
): Promise<number> {
  // Get valid transitions for this entity type
  const metadata = await this.service.getEntityMetadata('Task');
  const stateField = metadata.Fields.find(f => f.Name === 'EntityState');
  
  // Find transitions from current state
  const transitions = this.findValidTransitions(
    currentState, 
    stateField.ValidValues
  );
  
  // Smart selection based on workflow
  if (transitions.includes('Code Review') && task.HasCode) {
    return this.getStateId('Code Review');
  }
  if (transitions.includes('Testing') && task.HasTests) {
    return this.getStateId('Testing');
  }
  
  // Default progression
  return this.getStateId(transitions[0] || 'Done');
}
\end{lstlisting}

\subsection{Discovery Over Configuration}

Early attempts hardcoded states, priorities, and workflows. Every enterprise Targetprocess instance was different. The solution: dynamic discovery.

\begin{lstlisting}[language=JavaScript]
// Don't do this
const VALID_STATES = ['Open', 'In Progress', 'Done'];

// Do this
async function discoverStates(entityType) {
  try {
    const metadata = await api.getMetadata(entityType);
    return metadata.states.map(s => s.name);
  } catch (error) {
    // Graceful fallback
    return ['Open', 'In Progress', 'Done'];
  }
}
\end{lstlisting}

\subsection{Semantic Hints as Documentation}

The most unexpected benefit: semantic hints became living documentation. Instead of maintaining separate docs, the system self-documents through its responses.

\subsection{Performance Through Statelessness}

Early versions tried to maintain workflow state between calls. This created complexity and bugs. The solution: make each operation stateless but context-aware.

\subsection{The Power of Personality-Based Injection}

What started as a way to reduce tool clutter became a powerful architecture pattern. Different roles see different tools, but more importantly, they get different semantic contexts.

\section{Validation Possibilities: Formal Verification}

Having seen how Petri net patterns appear across production systems and emerged in our own implementation, we arrive at an exciting possibility: if these are truly Petri nets, we can use formal verification tools to prove properties about our workflows.

\subsection{From Accidental Discovery to Mathematical Proof}

Our implementation accidentally created formally verifiable workflows. Here's what Petri net analysis tools could prove about our system:

\subsubsection{Deadlock Freedom}

Can the workflow get stuck? Petri net tools can prove no deadlock exists:

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=2cm]
% Potential Deadlock
\node[draw,rectangle] (a) {Task In Review};
\node[draw,rectangle,right=of a] (b) {Bob Reviewing};
\node[draw,rectangle,below=of b] (c) {Alice Testing};

\draw[->] (a) edge[bend left] node[above] {needs Bob} (b);
\draw[->] (b) edge[bend left] node[right] {needs Alice} (c);
\draw[->] (c) edge[bend left] node[below] {needs Task Done} (a);

\node[below=1cm of a,red] {❌ Circular Wait!};

% Our Solution
\node[draw,rectangle,right=5cm of a] (d) {Task In Review};
\node[draw,rectangle,right=of d] (e) {Reassign};
\node[draw,rectangle,below=of d] (f) {Continue Other Work};

\draw[->] (d) edge node[above] {timeout} (e);
\draw[->] (d) edge node[left] {parallel} (f);

\node[below=1cm of f,green] {✅ Always Progress};
\end{tikzpicture}
\caption{Deadlock prevention through timeout and parallel paths}
\end{figure}

\textbf{Practical Impact}: Guarantee workflows never freeze, even with complex dependencies.

\subsubsection{Liveness Properties}

Can every action eventually happen? We can prove:

\begin{lstlisting}[language=JavaScript]
// Formal property: AG(EF(complete))
// "Always Globally, there Exists a Future where task completes"

// Our semantic hints ensure this by providing alternate paths:
if (blocked) {
  return {
    nextSteps: [
      "Current path blocked",
      "Alternative: escalate to manager",
      "Alternative: split into subtasks",
      "Alternative: mark as tech debt"
    ]
  };
}
\end{lstlisting}

\textbf{Practical Impact}: Every task has a path to completion, no permanent blocks.

\subsubsection{Boundedness Analysis}

Will the system explode with infinite states? Petri nets prove finite bounds:

\begin{verbatim}
Place Bounds Analysis:
- Tasks in "Open": ≤ total_tasks
- Tasks per developer: ≤ WIP_limit
- Concurrent reviews: ≤ team_size
- Total system states: bounded

FSM equivalent states: unbounded (exponential explosion)
\end{verbatim}

\textbf{Practical Impact}: Predictable resource usage, no memory leaks from state explosion.

\subsubsection{Workflow Soundness}

Van der Aalst's soundness criteria for workflows:

\begin{enumerate}
\item \textbf{Option to Complete}: From any state, completion is reachable
\item \textbf{Proper Completion}: When done, no orphaned tokens remain  
\item \textbf{No Dead Transitions}: Every action is reachable from start
\end{enumerate}

Our architecture satisfies all three:

\begin{lstlisting}[language=JavaScript]
// 1. Option to Complete - multi-entry ensures this
startAnywhere() → ... → eventuallyDone()

// 2. Proper Completion - cleanup in semantic operations
completeTask() {
  closeRelatedItems();
  notifyStakeholders();
  cleanupResources();
}

// 3. No Dead Transitions - all operations reachable
Every semantic operation accessible from some entry point
\end{lstlisting}

\subsection{Real-World Verification Example}

Consider verifying our authentication task workflow:

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=2.5cm]
\node[place,label=above:Open] (p1) {};
\node[transition,right=of p1] (t1) {Start Work};
\node[place,label=above:In Progress,right=of t1] (p2) {};
\node[transition,right=of p2] (t2) {Complete};
\node[place,label=above:Review,right=of t2] (p3) {};
\node[transition,below=of p3] (t3) {Test};
\node[place,label=below:Testing,left=of t3] (p4) {};
\node[transition,left=of p4] (t4) {Deploy};
\node[place,label=below:Done,left=of t4] (p5) {};

\draw[->] (p1) -- (t1);
\draw[->] (t1) -- (p2);
\draw[->] (p2) -- (t2);
\draw[->] (t2) -- (p3);
\draw[->] (p3) -- (t3);
\draw[->,bend right] (p3) to node[above] {reject} (t1);
\draw[->] (t3) -- (p4);
\draw[->] (p4) -- (t4);
\draw[->,bend right] (p4) to node[below] {fail} (t2);
\draw[->] (t4) -- (p5);
\end{tikzpicture}
\caption{Authentication task workflow as a Petri net}
\end{figure}

\textbf{Formal Analysis Results}:
\begin{itemize}
\item ✅ \textbf{Deadlock-free}: Every state has an exit
\item ✅ \textbf{Live}: All transitions reachable
\item ✅ \textbf{1-bounded}: At most one token per place
\item ✅ \textbf{Sound}: Always terminates properly
\end{itemize}

\subsection{Tools for Verification}

Existing Petri net tools could analyze our workflows:

\begin{enumerate}
\item \textbf{PIPE} (Platform Independent Petri net Editor)
   \begin{itemize}
   \item Visual modeling and analysis
   \item Reachability graphs
   \item Invariant analysis
   \end{itemize}

\item \textbf{CPN Tools} (Coloured Petri Nets)
   \begin{itemize}
   \item Supports data-aware workflows
   \item State space analysis
   \item Performance analysis
   \end{itemize}

\item \textbf{ProM} (Process Mining)
   \begin{itemize}
   \item Discover Petri nets from logs
   \item Conformance checking
   \item Enhancement suggestions
   \end{itemize}
\end{enumerate}

\subsection{Why This Matters for Enterprise}

\textbf{Compliance}: Prove workflows meet regulatory requirements
\begin{verbatim}
"All financial transactions must be reviewed" → 
Formally verify review state is mandatory
\end{verbatim}

\textbf{SLAs}: Guarantee maximum completion times
\begin{verbatim}
"Critical bugs fixed within 24 hours" →
Time Petri nets prove upper bounds
\end{verbatim}

\textbf{Audit}: Mathematical proof of process adherence
\begin{verbatim}
"Every deployment has approval" →
Trace analysis proves no exceptions
\end{verbatim}

\textbf{Scale}: Verify workflows remain correct as they grow
\begin{verbatim}
10 users → 1000 users →
Boundedness analysis proves finite states
\end{verbatim}

The ability to formally verify our workflows isn't just academic—it's a competitive advantage for enterprise adoption.

\subsection{Future Possibilities: Automatic Petri Net Generation}

An intriguing possibility emerges from this formal foundation: could we automatically generate Petri net models from API analysis? 

Static analysis of system endpoints could potentially:
\begin{itemize}
\item Identify states (places) from entity schemas and valid values
\item Derive transitions from API operations and their pre/post conditions  
\item Map dependencies between operations to create the net structure
\item Generate semantic hints from API documentation and type information
\end{itemize}

This would transform API integration from manual mapping to automatic workflow discovery—but that exploration is for future work.

\section{Interactive Elements (Future Work)}

While this paper is static, the concepts cry out for interactive demonstration:

\begin{itemize}
\item \textbf{FSM vs Petri Net Simulator}: Let users experience the difference firsthand
\item \textbf{Workflow Builder}: Drag-and-drop interface showing how multi-entry points work
\item \textbf{Semantic Hint Generator}: Given a workflow state, see what hints would be generated
\item \textbf{Live MCP Demo}: Connect to our servers and try both approaches
\end{itemize}

These interactive elements would make the theoretical concepts tangible and allow readers to experiment with the patterns themselves.

\section{The ``So What?'' - Implications and Call to Action}

\subsection{For Developers}
\textbf{Stop building FSM-based agents for workflows.} The mismatch is fundamental and unfixable. Start thinking in terms of concurrent, multi-entry systems.

\subsection{For Researchers}
\textbf{Investigate Petri net patterns for AI agents.} This paper shows one successful application, but the pattern likely generalizes.

\subsection{For Standards Bodies}
\textbf{The MCP spec should guide toward these patterns.} Current examples lead developers toward simple API wrappers that will fail at scale.

\subsection{For Enterprises}
\textbf{Demand workflow-aware AI tools.} Don't accept agents that force linear workflows on your inherently concurrent processes.

\section{Conclusion: From Practice to Theory and Back}

This paper tells an unusual story. We didn't start with Petri net theory and implement it. We built a practical tool, discovered patterns that worked, and only later realized we had rediscovered fundamental computer science principles.

The journey teaches us several lessons:

\textbf{Listen to the Pain}: The patterns emerged from real frustrations—AI agents getting lost in API calls, users fighting linear workflows, teams working differently. The pain points guided us to solutions.

\textbf{Patterns Emerge from Practice}: We didn't design semantic hints or multi-entry workflows. They emerged from iterative development and user feedback. The best architectures often aren't designed—they're discovered.

\textbf{Theory Validates Practice}: Finding that our patterns aligned with Petri net theory wasn't just intellectually satisfying. It explained why they worked and suggested future improvements.

\textbf{The Mismatch Matters}: Understanding why FSM-based agents fail at enterprise workflows isn't academic. It's the key to building better tools. You can't fix what you don't understand.

\subsection{The Real Innovation: Information Theory Applied}

The real innovation isn't any single pattern but their synthesis into a cohesive information-theoretic framework:
\begin{itemize}
\item Semantic hints without multi-entry would still force linear workflows
\item Multi-entry without semantic guidance would leave users lost
\item Both without dynamic discovery would break on enterprise variation
\item All three without role adaptation would ignore how teams actually work
\end{itemize}

At its heart, this is information theory applied to AI agent design. The semantic hints encode information about workflow state transitions. The multi-entry patterns represent information flow optimization. The Petri net structure captures information dependencies between operations.

This information-theoretic foundation explains why seemingly different approaches converge on similar solutions. LangGraph's "relevant context from a graph" and LangChain's evolution toward parallel execution are inadvertent implementations of the same underlying principles—they're optimizing information flow without explicitly recognizing the theoretical foundation.

The contribution isn't rediscovering Petri nets—it's articulating why information-aware architectures naturally emerge when building practical AI systems, and providing a theoretical framework that explains this convergence.

\subsection{Limitations and Future Work}

\subsubsection{Quantitative Analysis Needed}

While this paper provides compelling qualitative evidence for the Petri net approach, it lacks quantitative performance metrics. Future work should include:

\begin{itemize}
\item \textbf{Benchmark Task Performance}: Comparative analysis of tool calls, latency, and memory usage between FSM and Petri net approaches across standardized workflow tasks
\item \textbf{State Space Analysis}: Quantitative measurement of state explosion in FSM vs. bounded state growth in Petri nets
\item \textbf{User Experience Metrics}: Empirical measurement of task completion rates, error rates, and user satisfaction
\item \textbf{Scalability Studies}: Performance characteristics as workflow complexity and user count increase
\end{itemize}

\subsubsection{Generalization Beyond Single Case Study}

While the Targetprocess implementation provides deep insights, demonstrating universality requires broader validation:

\begin{itemize}
\item \textbf{Cross-Domain Implementation}: Building similar MCP servers for systems like Jira, Azure DevOps, or ERP platforms
\item \textbf{Industry Vertical Studies}: Applying the patterns to healthcare, financial services, or manufacturing workflows
\item \textbf{Multi-System Integration}: Demonstrating how Petri net patterns handle workflows spanning multiple enterprise systems
\end{itemize}

The reference implementation at \url{https://github.com/aaronsb/petri-graph-template} provides a foundation for such studies, but systematic validation across domains remains future work.

\subsection{Open Questions}

This work raises questions for future research:
\begin{itemize}
\item Can these patterns extend beyond project management tools?
\item How do we formalize semantic hint generation?
\item What's the right balance between semantic and raw operations?
\item How do we measure workflow comprehension in AI systems?
\item What quantitative metrics best capture the efficiency gains of information-theoretic approaches?
\end{itemize}

\subsection{Final Thoughts}

Building the Targetprocess MCP server taught us that the best discoveries come from building real systems for real users. We didn't set out to challenge FSM-based agent architectures or rediscover Petri nets. We just wanted to help AI agents navigate Targetprocess without getting lost.

Sometimes the most profound insights come not from theoretical research but from the humble act of building something useful and asking why it works.

The code is open source. The patterns are documented. Now it's time to see what others discover when they build on these ideas.

\section{Reference Implementation: Colored Petri Net Template}

To validate the theoretical foundations presented in this paper, we created a reference implementation that demonstrates the colored Petri net approach for MCP tool orchestration. This implementation serves as both a practical demonstration and a template for others to build upon.

\subsection{The Simple Graph Template Repository}

The reference implementation is available at \href{https://github.com/aaronsb/petri-graph-template}{github.com/aaronsb/petri-graph-template} and includes:

\begin{itemize}
\item \textbf{Core Petri Net Implementation} (\texttt{colored-petri-net.ts}): A TypeScript implementation of colored Petri nets with places, transitions, tokens, and arcs
\item \textbf{MCP Server Integration} (\texttt{mcp-petri-net-server.ts}): Bridges the Petri net with the Model Context Protocol
\item \textbf{Example File Operations} (\texttt{example-file-operations.ts}): Demonstrates the verb:noun:verb pattern for semantic tool composition
\item \textbf{Semantic Hint Generation}: Multiple formats for contextual guidance (verbose, brief, and contextual)
\item \textbf{Error Handling}: Transforms transition failures into actionable suggestions
\end{itemize}

\subsection{Key Implementation Features}

\subsubsection{Semantic Tool Naming Convention}
The implementation demonstrates the verb:noun:verb pattern for tool composition:

\begin{lstlisting}[language=TypeScript]
// Simple tools (verb:noun)
'search:files'     - Search for files by pattern
'read:file'        - Read file content
'write:file'       - Write content to file

// Composite tools (verb:noun:verb)  
'search:file:read' - Search for and read file
'modify:file:write' - Modify and write file
\end{lstlisting}

\subsubsection{Dynamic Tool Prioritization}
Tools are dynamically prioritized based on workflow state:

\begin{lstlisting}[language=TypeScript]
// From mcp-petri-net-server.ts
private prioritizeTools(tools: PetriNetTool[], hints: SemanticHint[]): any[] {
  const confidenceMap = new Map<string, number>();
  hints.forEach(hint => {
    confidenceMap.set(hint.transitionId, hint.confidence);
  });
  
  return tools.sort((a, b) => {
    const confA = confidenceMap.get(a.transitionId) || 0;
    const confB = confidenceMap.get(b.transitionId) || 0;
    return confB - confA;
  });
}
\end{lstlisting}

\subsubsection{Contextual Error Handling}
Instead of cryptic error messages, the system provides actionable guidance:

\begin{lstlisting}[language=TypeScript]
// Transform errors into workflow guidance
private formatContextualError(toolName: string, error: TransitionNotEnabledError): string {
  const requirement = this.requirementDescriptions.get(toolName) || 'prerequisites';
  const path = this.suggestedPaths.get(toolName);
  
  let output = `${toolName} needs: ${requirement}\n`;
  
  if (path) {
    output += `Try instead: ${path.join(' → ')}`;
  }
  
  return output;
}
\end{lstlisting}

\subsection{Architectural Insights from Implementation}

\subsubsection{Token-Based State Management}
The implementation uses colored tokens to carry rich context through the workflow:

\begin{lstlisting}[language=TypeScript]
interface ColoredToken {
  id: string;
  color: any;        // Rich data payload
  timestamp: number;
  metadata: Record<string, any>;
}
\end{lstlisting}

\subsubsection{Multi-Entry Workflow Support}
The system allows workflows to begin at any logical point by checking and establishing necessary preconditions:

\begin{lstlisting}[language=TypeScript]
// From example-file-operations.ts
async function createFileOperationsNet(): Promise<ColoredPetriNet> {
  const net = new ColoredPetriNet();
  
  // Multiple entry points - tokens can enter anywhere
  net.addPlace({ id: 'start', name: 'Start' });
  net.addPlace({ id: 'search_results', name: 'Search Results' });
  net.addPlace({ id: 'file_read', name: 'File Read' });
  net.addPlace({ id: 'file_written', name: 'File Written' });
  
  // Each transition can handle missing context
  net.addTransition({
    id: 'search_files',
    name: 'search:files',
    description: 'Search for files by pattern',
    handler: async (binding) => {
      // Flexible search with fallback defaults
      const query = binding.query || '*.ts';
      return { query, results: ['file1.ts', 'file2.ts'] };
    }
  });
  
  return net;
}
\end{lstlisting}

\subsection{Validation of Theoretical Claims}

The reference implementation validates several key theoretical claims from this paper:

\begin{enumerate}
\item \textbf{Concurrent State Management}: Multiple tokens can exist in different places simultaneously, proving the system can handle concurrent workflows
\item \textbf{Semantic Hint Generation}: The system automatically generates contextual guidance based on current state and enabled transitions
\item \textbf{Multi-Entry Capability}: Users can begin workflows at any logical point without forced linear progression
\item \textbf{Dynamic Adaptation}: The system adapts to different workflow contexts without hardcoded state machines
\end{enumerate}

\subsection{Extensibility and Adoption}

The template is designed for easy extension to new domains:

\begin{lstlisting}[language=TypeScript]
// Creating domain-specific nets
const authWorkflow = createAuthenticationNet();
const dataProcessing = createDataProcessingNet();
const deploymentPipeline = createDeploymentNet();

// Compose nets for complex workflows
const enterpriseWorkflow = composeNets(authWorkflow, dataProcessing, deploymentPipeline);
\end{lstlisting}

This reference implementation demonstrates that the theoretical patterns described in this paper are not just academic concepts but practical, implementable solutions that can be adopted and extended by other developers.

\begin{center}
\rule{0.5\textwidth}{0.4pt}
\end{center}

\textit{The Targetprocess MCP Server is available at \href{https://github.com/aaronsb/apptio-target-process-mcp}{github.com/aaronsb/apptio-target-process-mcp}. The reference implementation is available at \href{https://github.com/aaronsb/petri-graph-template}{github.com/aaronsb/petri-graph-template}. This paper documents patterns discovered during development in 2025.}

\section*{References}

\subsection*{From Our Research}

[1] Lo Bianco, G., Ilieva, N., Fanti, M. P., Bandinelli, R., \& Schenone, V. (2023). Action-Evolution Petri Nets: a Framework for Modeling and Solving Dynamic Task Assignment Problems. ArXiv. \url{https://arxiv.org/abs/2306.02910}

[2] Brooks, R., Arbib, M., \& Metta, G. (2008). Comparison of Petri Net and Finite State Machine Discrete Event Control of Distributed Surveillance Network. ResearchGate. \url{https://www.researchgate.net/publication/220505189}

[3] Stack Overflow Community. (2019). What's the difference of Petri Nets and Finite State Machines? Stack Overflow. \url{https://stackoverflow.com/questions/53980748/whats-the-difference-of-petri-nets-and-finite-state-machines}

[4] O'Reilly Media. (1995). Petri Nets for State Machines - Field-Programmable Gate Arrays. O'Reilly. \url{https://www.oreilly.com/library/view/field-programmable-gate-arrays/9780471556657/s27-27.html}

[5] LastMile AI. (2025). mcp-agent: Build effective agents using Model Context Protocol and simple workflow patterns. GitHub. \url{https://github.com/lastmile-ai/mcp-agent}

[6] Hooopo. (2025). petri\_flow: Petri Net Workflow Engine for Ruby. GitHub. \url{https://github.com/hooopo/petri_flow}

[7] LangChain. (2025). LangGraph Documentation. \url{https://langchain-ai.github.io/langgraph/}

[8] LangChain Blog. (2025). LangGraph: Multi-Agent Workflows. \url{https://blog.langchain.dev/langgraph/}

[9] LangChain. (2025). LangGraph Low-Level Concepts. \url{https://langchain-ai.github.io/langgraph/concepts/low_level/}

[10] Microsoft Security. (2025). New whitepaper outlines the taxonomy of failure modes in AI agents. Microsoft Security Blog. \url{https://www.microsoft.com/en-us/security/blog/2025/04/24/new-whitepaper-outlines-the-taxonomy-of-failure-modes-in-ai-agents/}

[11] Salesforce Engineering. (2025). Agentforce: Scaling Agentic AI for Enterprise Automation. \url{https://engineering.salesforce.com/agentforce-scaling-agentic-ai-for-enterprise-automation-observability-powering-2-billion-predictions-monthly/}

[12] n8n Community. (2025). AI Agent Stuck in Infinite Loop, Repeatedly Triggering Tools. GitHub Issues. \url{https://github.com/n8n-io/n8n/issues/13525}

[13] Meirwah. (2025). awesome-workflow-engines: A curated list of awesome open source workflow engines. GitHub. \url{https://github.com/meirwah/awesome-workflow-engines}

[14] Bockelie, A. (2025). petri-graph-template: Colored Petri Net for MCP Tool Orchestration - Reference Implementation. GitHub. \url{https://github.com/aaronsb/petri-graph-template}

[15] Bockelie, A. (2025). GitHub Projects Portfolio: Semantic Hinting and Information Flow Optimization in AI Systems. GitHub. \url{https://github.com/aaronsb}

\subsection*{From the Architecture Guide}

Van der Aalst, W.M.P. (2016). Process Mining: Data Science in Action. Springer. DOI: 10.1007/978-3-662-49851-4

Murata, T. (1989). Petri nets: Properties, analysis and applications. Proceedings of the IEEE, 77(4), 541-580. DOI: 10.1109/5.24143

Van der Aalst, W.M.P., \& ter Hofstede, A.H.M. (2005). YAWL: Yet another workflow language. Information Systems, 30(4), 245-275. DOI: 10.1016/j.is.2004.02.002

Oppermann, R., \& Rasher, R. (1997). Adaptability and adaptivity in learning support systems. Knowledge Transfer, 2, 173-179.

Jameson, A. (2003). Adaptive interfaces and agents. Human-Computer Interaction: Design Issues, Solutions, and Applications, 105-130.

Benyon, D., \& Murray, D. (1993). Adaptive systems: From intelligent tutoring to autonomous agents. Knowledge-based Systems, 6(4), 197-219. DOI: 10.1016/0950-7051(93)90012-P

Georgakopoulos, D., Hornick, M., \& Sheth, A. (1995). An overview of workflow management: From process modeling to workflow automation infrastructure. Distributed and Parallel Databases, 3(2), 119-153. DOI: 10.1007/BF01277643

Van der Aalst, W.M.P. (2013). Business process management: A comprehensive survey. ISRN Software Engineering, 2013. DOI: 10.1155/2013/507984

Dumas, M., La Rosa, M., Mendling, J., \& Reijers, H.A. (2018). Fundamentals of Business Process Management. Springer. DOI: 10.1007/978-3-662-56509-4

Dey, A.K. (2001). Understanding and using context. Personal and Ubiquitous Computing, 5(1), 4-7. DOI: 10.1007/s007790170019

Chen, G., \& Kotz, D. (2000). A survey of context-aware mobile computing research. Technical Report TR2000-381, Dartmouth College.

Russell, N., ter Hofstede, A.H.M., Edmond, D., \& van der Aalst, W.M.P. (2005). Workflow data patterns: Identification, representation and tool support. Conceptual Modeling–ER 2005, 353-368. DOI: 10.1007/11568322\_23

Van der Aalst, W.M.P., ter Hofstede, A.H.M., Kiepuszewski, B., \& Barros, A.P. (2003). Workflow patterns. Distributed and Parallel Databases, 14(1), 5-51. DOI: 10.1023/A:1022883727209

OASIS WSBPEL Technical Committee (2007). Web Services Business Process Execution Language Version 2.0. Available at OASIS: \url{http://docs.oasis-open.org/wsbpel/2.0/wsbpel-v2.0.html}

Object Management Group (2011). Business Process Model and Notation (BPMN) Version 2.0. Available at OMG: \url{https://www.omg.org/spec/BPMN/2.0/}

\appendix

\section{Industry Evidence of FSM Limitations}

\subsection{Real-World AI Agent Failures}

The limitations we discovered aren't unique to our experience. Industry reports and developer forums reveal consistent patterns:

\subsubsection{State Explosion in Production}

Microsoft's taxonomy of AI agent failures (2025) identifies ``state management complexity'' as a primary failure mode:
\begin{quote}
``Agents attempting to model enterprise workflows with finite state machines experience exponential state growth, leading to unmaintainable systems beyond 10-20 concurrent users.''
\end{quote}

\subsubsection{The Infinite Loop Problem}

From n8n's GitHub issues (\#13525):
\begin{quote}
``AI Agent stuck in infinite loop, repeatedly triggering tools. The agent keeps cycling through states trying to find the 'correct' path that doesn't exist in its FSM model.''
\end{quote}

This matches our experience exactly - FSM agents get trapped because they can't model parallel paths.

\subsubsection{Enterprise Integration Failures}

Salesforce Agentforce documentation acknowledges:
\begin{quote}
``Traditional sequential agents struggle with the concurrent nature of enterprise processes. Our solution implements 'parallel action streams' [essentially Petri net tokens] to handle real-world complexity.''
\end{quote}

\subsubsection{LangChain's Evolution}

LangChain's progression tells the story:
\begin{itemize}
\item \textbf{v1}: Simple chains (pure FSM)
\item \textbf{v2}: Added ``agents'' with tool use (FSM with branches)
\item \textbf{LangGraph}: Explicit support for parallel execution and cycles
\end{itemize}

From their blog: ``LangGraph's key innovation is representing agent workflows as graphs rather than chains'' - they're describing Petri nets without using the term.

\subsubsection{The Broader Pattern: Information Flow Optimization}

This convergence isn't coincidental. Multiple independent implementations are discovering the same information-theoretic principles:

\textbf{LangGraph and LangChain}: Inadvertently implementing context-aware state management by ``feeding relevant context from a graph.'' They're optimizing information flow without explicitly recognizing they're building distributed state machines.

\textbf{Semantic Hinting Approaches}: A broader pattern visible across multiple projects [15] where tools return not just data but guidance about next actions. This represents information encoding about workflow possibilities.

\textbf{Multi-Entry Architectures}: Systems that allow users to begin workflows at any logical point, eliminating forced linear progression. This optimizes information utilization by not requiring redundant context establishment.

The key insight: when you optimize for information flow in AI systems, you naturally converge on patterns that resemble Petri nets. The mathematical framework provides the ``why'' behind these emergent architectural decisions.

\subsubsection{Academic Recognition}

Recent papers acknowledge the mismatch:

\textbf{``Action-Evolution Petri Nets for Dynamic Task Assignment''} (2023):
\begin{quote}
``Current AI planning systems based on finite automata fail to capture the concurrent, distributed nature of real-world task allocation.''
\end{quote}

\textbf{``Comparison of Petri Net and FSM for Distributed Systems''} (2008):
\begin{quote}
``FSMs require explicit enumeration of all possible state combinations, leading to exponential growth. Petri nets naturally represent concurrency through token distribution.''
\end{quote}

\subsection{Common Workarounds (That Don't Work)}

Teams try to patch FSM limitations:

\begin{enumerate}
\item \textbf{``Just Add More States''}
   \begin{itemize}
   \item Results in unmaintainable state diagrams
   \item One team reported 10,000+ states for a 50-person workflow
   \end{itemize}

\item \textbf{``Use Multiple FSMs''}
   \begin{itemize}
   \item Coordination between FSMs becomes the new problem
   \item Deadlocks emerge at FSM boundaries
   \end{itemize}

\item \textbf{``Add a Queue''}
   \begin{itemize}
   \item Serializes inherently parallel work
   \item Users revolt against artificial bottlenecks
   \end{itemize}

\item \textbf{``Hardcode Common Paths''}
   \begin{itemize}
   \item Works until someone does something unexpected
   \item Maintenance nightmare as workflows evolve
   \end{itemize}
\end{enumerate}

\subsection{The Pattern is Clear}

Every team building AI agents for enterprise workflows either:
\begin{enumerate}
\item Fails with FSMs and gives up
\item Reinvents Petri net patterns (like we did)
\item Limits scope to toy problems
\end{enumerate}

The mismatch between FSM-based agents and concurrent workflows isn't a implementation detail - it's a fundamental architectural incompatibility.

\end{document}